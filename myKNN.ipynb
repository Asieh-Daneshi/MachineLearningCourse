{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with kNN\n",
    "<p style=font-size:20px;color:rgba(255,255,255,255);> This is the second session of our machine learning journey!</p>\n",
    "<p style=font-size:14px;color:rgba(255,255,255,255);> Here we apply kNN on our the data!</p>\n",
    "<p style=font-size:20px;color:yellow;> Importing required libraries </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# pip install numpy\n",
    "import pandas as pd\n",
    "# pip install pandas\n",
    "import matplotlib.pyplot as plt \n",
    "# pip install matplotlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# pip install sikit-learn   # for sklearn\n",
    "# pip install preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# pip install imblearn\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================================================================================\n",
    "<p style=font-size:25px;color:yellow;> Download dataset </p>\n",
    "https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=color:yellow;font-size:20xp> Openning the csv file, changing the name of the columns, showing the first five columns </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]        # name of the columns from the other file called \"magic04.names\"\n",
    "\n",
    "df = pd.read_csv(\"magic04.data\", names=cols)      # reading the dataset again, but this time we are naming the columns\n",
    "\n",
    "df.head()        # shows the first five rows of df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=color:yellow;font-size:20xp;>Changing the character labels into numbers</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this blick, we want to see which feature (label) can separate data classes better. We plot histograms, and the one/ those\n",
    "# that look more separable, are better for our classification goal\n",
    "# Based on the plots that come below, we see that it seems 'fAlpha' is the best feature for our purpose!\n",
    "df[\"class\"].unique()        # shows all the different elements in the column labled \"class\"; exactly like unique in MATLAB\n",
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)      # compares the elements in the \"class\" column with \"g\" and returns \"True\" or \"Flase\". Then converts these binaries into integers 1 and 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================================================================================\n",
    "# Train, validation, test datasets\n",
    "<p style=color:yellow;font-size:20xp> First 60% as train, from 60% to 80% as validation, the rest as test </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = np.split(df.sample(frac=1, replace=False), [int(0.6*len(df)), int(0.8*len(df))])\n",
    "# Note:\n",
    "# Randomly sample 30% of the rows with replacement and a specific random state\n",
    "# random_sample_with_replace = df.sample(frac=0.3, replace=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================================================================================\n",
    "<p style=color:yellow;font-size:25xp;>Writing a function that gets data, z-scores each column of data, and balances them (either oversample or undersample), in a way that all of them have the same number of elements </p>\n",
    "<p style=color:rgba(0,255,0,255);font-size:25xp;>Balancing is kind of necessary for KNN; otherwise, the larger class can affect our classification! </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a function called 'scale-dataset' for scaling the data\n",
    "def scale_dataset(dataframe, oversample, undersample):\n",
    "    X = dataframe[dataframe.columns[:-1]].values    # '.columns[:-1] refers to all the columns except than the last column\n",
    "    Y = dataframe[dataframe.columns[-1]].values     # '.columns[-1]' refers to the last column, '.values' turns dataframe into matrix\n",
    "    \n",
    "    # here we put 'StandardScaler()' in a separate variable called 'scaler' to make using it easier. Instead of the next two lines, we could write \"StandardScaler().fit_transform(X)\"\n",
    "    scaler = StandardScaler()       # StandardScaler transforms the data in a way that it has zero mean and a standard deviation of 1.   \n",
    "    X = scaler.fit_transform(X)     # fit_transform finds the mean and std of each column of data. Then for all the element of each column, subtracts the mean of them, and divides the result to the std\n",
    "    # fit_transform and StandardScaler together work as z-tansform\n",
    "    if oversample:\n",
    "        # here we put 'RandomOverSampler()' in a separate variable calles 'ros' to make using it easier\n",
    "        ros = RandomOverSampler()   \n",
    "        X, Y = ros.fit_resample(X, Y)       \n",
    "        # 'fit_resample' picks samples from 'X' for each group of 'Y'. In this example Y includes two groups 1, and 0. Now, using 'OverSampler'\n",
    "        # means that if one of these groups has less members than the other group, it randomly picks some elements from that group again (repeat them)\n",
    "        # in a way that at the end both group have the same number of elements (the size of the larger group)\n",
    "\n",
    "    if undersample:\n",
    "        # here we put 'RandomUnderSampler()' in a separate variable calles 'rus' to make using it easier\n",
    "        rus = RandomUnderSampler()   \n",
    "        X, Y = rus.fit_resample(X, Y)       \n",
    "        # 'fit_resample' picks samples from 'X' for each group of 'Y'. In this example Y includes two groups 1, and 0. Now, using 'OverSampler'\n",
    "        # means that if one of these groups has less members than the other group, it randomly removes some elements from larger group in a way\n",
    "        # that at the end both group have the same number of elements (the size of the smaller group)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(Y, (-1,1))))        # '-1' in 'reshape' means that we leave that dimension unassigned, meaning that here the result has one column, but the number of rows is not assigned\n",
    "    # hstack horizontally stacks the input arrays\n",
    "    return data, X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================================================================================\n",
    "<p style=color:yellow;font-size:25px;>Testing the function that we wrote in the previous block</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================================================================================\n",
    "## Using our function to take samples from data for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, Xtrain, Ytrain = scale_dataset(train, oversample=True, undersample=False)\n",
    "valid, Xvalid, Yvalid = scale_dataset(valid, oversample=False, undersample=False)\n",
    "test, Xtest, Ytest = scale_dataset(test, oversample=False, undersample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=color:yellow;font-size:40px;>kNN</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = knn_model.predict(Xtest)\n",
    "# print(Ypred)\n",
    "# print(Ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1284\n",
      "           1       0.87      0.86      0.87      2520\n",
      "\n",
      "    accuracy                           0.82      3804\n",
      "   macro avg       0.80      0.80      0.80      3804\n",
      "weighted avg       0.82      0.82      0.82      3804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Ytest,Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=color:rgba(0,255,0,255);font-size:25xp;>Evaluating the accuracy of our classification (just accuracy, not the whole report!)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823080967402734"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Ytest, Ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=color:rgba(255,255,0,255);font-size:25xp;>Testing different number of neighbors for KNN to find the best one!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is:  0.8448837735567615\n",
      "Best number of neighbors:  3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Ks = np.arange(3,20,2)\n",
    "best_score = -1\n",
    "best_K = None\n",
    "\n",
    "for k in Ks:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "    average_score = np.mean(scores)\n",
    "\n",
    "    if average_score > best_score:\n",
    "        best_score = average_score\n",
    "        best_K = k\n",
    "\n",
    "print(\"Best score is: \", best_score)\n",
    "print(\"Best number of neighbors: \", best_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=color:rgba(255,255,0,255);font-size:25xp;>Testing different algorithms for finding the distance between points on KNN to find the best one!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is:  0.8448837735567615\n",
      "Best number of neighbors:  3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "best_score = -1\n",
    "best_K = None\n",
    "\n",
    "for k in Ks:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "    scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "    average_score = np.mean(scores)\n",
    "\n",
    "    if average_score > best_score:\n",
    "        best_score = average_score\n",
    "        best_K = k\n",
    "\n",
    "print(\"Best score is: \", best_score)\n",
    "print(\"Best number of neighbors: \", best_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manhattan\n",
      "0.8470613155028118\n"
     ]
    }
   ],
   "source": [
    "best_score = -1\n",
    "best_distance = None\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'euclidean'\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'manhattan'\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=2)\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'minkowski'\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='chebyshev')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'chebyshev'\n",
    "# ----------------------------------------------------------------------------------\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=11, metric='mahalanobis')\n",
    "# knn_model.fit(Xtrain, Ytrain)\n",
    "# Ypred = knn_model.predict(Xtest)\n",
    "# allAccuracies.append(accuracy_score(Ytest, Ypred))\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='hamming')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'hamming'\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='canberra')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'canberra'\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'cosine'\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='jaccard')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'jaccard'\n",
    "# ----------------------------------------------------------------------------------\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='braycurtis')\n",
    "scores = cross_val_score(knn_model, Xtrain, Ytrain, cv=5)  # 5-fold cross-validation\n",
    "average_score = np.mean(scores)\n",
    "\n",
    "if average_score > best_score:\n",
    "    best_score = average_score\n",
    "    best_distance = 'braycurtis'\n",
    "# ----------------------------------------------------------------------------------\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=11, metric='haversine')\n",
    "# knn_model.fit(Xtrain, Ytrain)\n",
    "# Ypred = knn_model.predict(Xtest)\n",
    "# allAccuracies.append(accuracy_score(Ytest, Ypred))\n",
    "\n",
    "\n",
    "print(best_distance)\n",
    "print(best_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
